# -*- coding: utf-8 -*-
"""Untitled30.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wrycoAK1mr-VXEEl0KxOvJILp53Q7LuP
"""

# Install required libraries
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

store_sales = pd.read_csv('/content/train.csv')

store_sales.head(10)

store_sales.info()

# Drop 'store' and 'item' column
new_salesdata = store_sales.drop(['store','item'], axis=1)

new_salesdata

#Convert date column to DateTime data type
new_salesdata['date'] = pd.to_datetime(new_salesdata['date'])

new_salesdata

# Convert the date to a period of 'Month'
new_salesdata['date'] = new_salesdata['date'].dt.to_period('M')
monthly_sales=new_salesdata.groupby('date').sum().reset_index()

monthly_sales['date']=monthly_sales['date'].dt.to_timestamp()

monthly_sales.head(10)

# Data visualization
plt.figure(figsize=(20,5))
plt.plot(monthly_sales['date'], monthly_sales['sales'])
plt.xlabel('Date')
plt.ylabel('Sales')
plt.title("Sales over the Months")
plt.show()

#Calculate monthly sales difference

monthly_sales['sales_diff'] = monthly_sales['sales'].diff()
monthly_sales = monthly_sales.dropna()
monthly_sales.head()

plt.figure(figsize=(15,5))
plt.plot(monthly_sales['date'], monthly_sales['sales_diff'])
plt.xlabel('Date')
plt.ylabel('Sales')
plt.title("Monthly Sales")
plt.show()





"""**Logistic Regression**"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

from sklearn.datasets import load_breast_cancer

df=load_breast_cancer()
#Independent features
X=pd.DataFrame(df['data'], columns=df['feature_names'])

X.head()

#Dependent Features
y=pd.DataFrame(df['target'], columns=['Target'])
y

y['Target'].value_counts()

# Train, test split

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=42)

X_train

params=[{'C':[1,5,10]}, {'max_iter':[100,150]}]

model1=LogisticRegression(C=100, max_iter=100)

model=GridSearchCV(model1,param_grid=params,scoring='f1', cv=5)

model.fit(X_train,y_train)

model.best_params_

model.best_score_

y_pred=model.predict(X_test)

y_pred

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

confusion_matrix(y_test, y_pred)

accuracy_score(y_test, y_pred)

print(classification_report(y_test, y_pred))



"""************
************
************

"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.datasets import load_iris

iris=load_iris()

iris.data

from sklearn.tree import DecisionTreeClassifier

classifier=DecisionTreeClassifier()
classifier.fit(iris.data, iris.target)

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(classifier, filled=True)





"""**Performance Metrics Clustering-Silhoutter Coefficient**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score

# generating teh sample data from make_blobs
# This perticular setting has one distinct cluster and 3 clusters placed close together

X,y = make_blobs(n_samples=500,
                 n_features=2,
                 centers)





